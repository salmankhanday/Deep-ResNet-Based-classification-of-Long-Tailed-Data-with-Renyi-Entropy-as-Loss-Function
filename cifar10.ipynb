{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmankhanday/Deep-ResNet-Based-classification-of-Long-Tailed-Data-with-Renyi-Entropy-as-Loss-Function/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7YPLWAdwn4s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOBG3TcnkLh7",
        "outputId": "5abb9c7e-eb81-4e8e-a678-f0f7bf4d1794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ResLT'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 154 (delta 62), reused 90 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (154/154), 13.14 MiB | 6.87 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jiequancui/ResLT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xsIPAHcwrVz"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "os.chdir(\"/content/ResLT/CIFAR\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYSNF8hZw0PU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zVvGdfIy0Y8",
        "outputId": "269bf51a-0bd3-42d2-9087-c199ee2e0fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt/proj56/jqcui/Data/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15738171.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /mnt/proj56/jqcui/Data/cifar10/cifar-10-python.tar.gz to /mnt/proj56/jqcui/Data/cifar10\n",
            "12406\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class IMBALANCECIFAR10(torchvision.datasets.CIFAR10):\n",
        "    cls_num = 10\n",
        "    data_path=\"/mnt/proj56/jqcui/Data/cifar10\"\n",
        "    def __init__(self, root=None, imb_type='exp', imb_factor=0.01, rand_number=0, train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False, class_balance=False):\n",
        "        root=self.data_path\n",
        "        super(IMBALANCECIFAR10, self).__init__(root, train, transform, target_transform, download)\n",
        "        np.random.seed(rand_number)\n",
        "        img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, imb_factor)\n",
        "        self.gen_imbalanced_data(img_num_list)\n",
        "\n",
        "        self.class_balance = class_balance\n",
        "        if class_balance:\n",
        "           self.class_data=[ [] for i in range(self.cls_num) ]\n",
        "           for i in range(len(self.targets)):\n",
        "              self.class_data[self.targets[i]].append(i)\n",
        "\n",
        "    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n",
        "        img_max = len(self.data) / cls_num\n",
        "        img_num_per_cls = []\n",
        "        if imb_type == 'exp':\n",
        "            for cls_idx in range(cls_num):\n",
        "                num = img_max * (imb_factor**(cls_idx / (cls_num - 1.0)))\n",
        "                img_num_per_cls.append(int(num))\n",
        "        elif imb_type == 'step':\n",
        "            for cls_idx in range(cls_num // 2):\n",
        "                img_num_per_cls.append(int(img_max))\n",
        "            for cls_idx in range(cls_num // 2):\n",
        "                img_num_per_cls.append(int(img_max * imb_factor))\n",
        "        else:\n",
        "            img_num_per_cls.extend([int(img_max)] * cls_num)\n",
        "        return img_num_per_cls\n",
        "\n",
        "    def gen_imbalanced_data(self, img_num_per_cls):\n",
        "        new_data = []\n",
        "        new_targets = []\n",
        "        targets_np = np.array(self.targets, dtype=np.int64)\n",
        "        classes = np.unique(targets_np)\n",
        "        # np.random.shuffle(classes)\n",
        "        self.num_per_cls_dict = dict()\n",
        "        for the_class, the_img_num in zip(classes, img_num_per_cls):\n",
        "            self.num_per_cls_dict[the_class] = the_img_num\n",
        "            idx = np.where(targets_np == the_class)[0]\n",
        "            np.random.shuffle(idx)\n",
        "            selec_idx = idx[:the_img_num]\n",
        "            new_data.append(self.data[selec_idx, ...])\n",
        "            new_targets.extend([the_class, ] * the_img_num)\n",
        "        new_data = np.vstack(new_data)\n",
        "        self.data = new_data\n",
        "        self.targets = new_targets\n",
        "        print(len(new_targets))\n",
        "       \n",
        "    def get_cls_num_list(self):\n",
        "        cls_num_list = []\n",
        "        for i in range(self.cls_num):\n",
        "            cls_num_list.append(self.num_per_cls_dict[i])\n",
        "        return cls_num_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "          if self.class_balance:\n",
        "             sample_class = random.randint(0, self.cls_num - 1)\n",
        "             index = random.choice(self.class_data[sample_class])\n",
        "             img, target = self.data[index], sample_class \n",
        "          else:\n",
        "             img, target = self.data[index], self.targets[index]\n",
        "          img = Image.fromarray(img)\n",
        "          if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "          return img, target \n",
        "\n",
        "\n",
        "class IMBALANCECIFAR100(IMBALANCECIFAR10):\n",
        "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "    This is a subclass of the `CIFAR10` Dataset.\n",
        "    \"\"\"\n",
        "    base_folder = 'cifar-100-python'\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
        "    filename = \"cifar-100-python.tar.gz\"\n",
        "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
        "    train_list = [\n",
        "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
        "    ]\n",
        "\n",
        "    test_list = [\n",
        "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
        "    ]\n",
        "    meta = {\n",
        "        'filename': 'meta',\n",
        "        'key': 'fine_label_names',\n",
        "        'md5': '7973b15100ade9c7d40fb424638fde48',\n",
        "    }\n",
        "    cls_num = 100\n",
        "    data_path=\"/mnt/proj56/jqcui/Data/cifar100\"\n",
        "\n",
        "\n",
        "class CIFAR10V2(object):\n",
        "    def __init__(self, batch_size=128, class_balance=False, imb_factor=None):\n",
        "        mean = [0.4914, 0.4822, 0.4465]\n",
        "        std = [0.2023, 0.1994, 0.2010]\n",
        "        normalize = transforms.Normalize(mean, std)\n",
        "        transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        trainset = IMBALANCECIFAR10(root=\"/mnt/proj56/jqcui/Data/cifar10\", train=True, transform=transform_train, download=False, imb_factor=imb_factor, class_balance=class_balance)\n",
        "        testset = datasets.CIFAR10(root='/mnt/proj56/jqcui/Data/cifar10', train=False, transform=transform_test, download=False)\n",
        "\n",
        "        self.train = torch.utils.data.DataLoader(\n",
        "            trainset,\n",
        "            batch_size = batch_size, shuffle = True,\n",
        "            num_workers = 8, pin_memory = True, drop_last=True)\n",
        "\n",
        "        self.test = torch.utils.data.DataLoader(\n",
        "            testset,\n",
        "            batch_size = batch_size, shuffle = False,\n",
        "            num_workers = 4, pin_memory = True)\n",
        "\n",
        "class CIFAR10V2_auto(object):\n",
        "    def __init__(self, batch_size=128, class_balance=False, imb_factor=None):\n",
        "        mean = [0.4914, 0.4822, 0.4465]\n",
        "        std = [0.2023, 0.1994, 0.2010]\n",
        "        normalize = transforms.Normalize(mean, std)\n",
        "        transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                CIFAR10Policy(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        trainset = IMBALANCECIFAR10(root=\"/mnt/proj56/jqcui/Data/cifar10\", train=True, transform=transform_train, download=False, imb_factor=imb_factor, class_balance=class_balance)\n",
        "        testset = datasets.CIFAR10(root='/mnt/proj56/jqcui/Data/cifar10', train=False, transform=transform_test, download=False)\n",
        "\n",
        "        self.train = torch.utils.data.DataLoader(\n",
        "            trainset,\n",
        "            batch_size = batch_size, shuffle = True,\n",
        "            num_workers = 8, pin_memory = True, drop_last=True)\n",
        "\n",
        "        self.test = torch.utils.data.DataLoader(\n",
        "            testset,\n",
        "            batch_size = batch_size, shuffle = False,\n",
        "            num_workers = 4, pin_memory = True)\n",
        "\n",
        "class CIFAR100V2(object):\n",
        "    def __init__(self, batch_size=128, class_balance=False, dual_sampler=False, imb_factor=None):\n",
        "        mean = [0.4914, 0.4822, 0.4465]\n",
        "        std = [0.2023, 0.1994, 0.2010]\n",
        "        normalize = transforms.Normalize(mean, std)\n",
        "        transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        trainset = IMBALANCECIFAR100(root='/mnt/proj56/jqcui/Data/cifar100', train=True, transform=transform_train, download=False, imb_factor=imb_factor, class_balance=class_balance)\n",
        "        testset = datasets.CIFAR100(root='/mnt/proj56/jqcui/Data/cifar100', train=False, transform=transform_test, download=False)\n",
        "\n",
        "        self.train = torch.utils.data.DataLoader(\n",
        "            trainset,\n",
        "            batch_size = batch_size, shuffle = True,\n",
        "            num_workers = 8, pin_memory = True, drop_last=True)\n",
        "\n",
        "        self.test = torch.utils.data.DataLoader(\n",
        "            testset,\n",
        "            batch_size = batch_size, shuffle = False,\n",
        "            num_workers = 4, pin_memory = True)\n",
        "\n",
        "class CIFAR100V2_auto(object):\n",
        "    def __init__(self, batch_size=128, class_balance=False, dual_sampler=False, imb_factor=None):\n",
        "        mean = [0.4914, 0.4822, 0.4465]\n",
        "        std = [0.2023, 0.1994, 0.2010]\n",
        "        normalize = transforms.Normalize(mean, std)\n",
        "        transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                CIFAR10Policy(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        trainset = IMBALANCECIFAR100(root='/mnt/proj56/jqcui/Data/cifar100', train=True, transform=transform_train, download=False, imb_factor=imb_factor, class_balance=class_balance)\n",
        "        testset = datasets.CIFAR100(root='/mnt/proj56/jqcui/Data/cifar100', train=False, transform=transform_test, download=False)\n",
        "\n",
        "        self.train = torch.utils.data.DataLoader(\n",
        "            trainset,\n",
        "            batch_size = batch_size, shuffle = True,\n",
        "            num_workers = 8, pin_memory = True, drop_last=True)\n",
        "\n",
        "        self.test = torch.utils.data.DataLoader(\n",
        "            testset,\n",
        "            batch_size = batch_size, shuffle = False,\n",
        "            num_workers = 4, pin_memory = True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    trainset = IMBALANCECIFAR10(root='/mnt/proj56/jqcui/Data/cifar10', train=True,\n",
        "                    download=True, transform=transform)\n",
        "    trainloader = iter(trainset)\n",
        "    data, label = next(trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIvSSOew3VM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RenyiEntropyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5):\n",
        "        super(RenyiEntropyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def forward(self, input, target):\n",
        "        n = input.size()[0]\n",
        "        log_prob = nn.functional.log_softmax(input, dim=1)\n",
        "        y_onehot = torch.zeros_like(log_prob)\n",
        "        y_onehot.scatter_(1, target.view(-1, 1), 1)\n",
        "        \n",
        "        # compute Renyi entropy loss\n",
        "        loss = (1/(1-self.alpha))*torch.log(torch.sum(torch.exp(self.alpha*log_prob)*y_onehot, dim=1)) + \\\n",
        "               (1/self.alpha)*torch.log(torch.sum(torch.exp((1-self.alpha)*log_prob)*(1-y_onehot), dim=1))\n",
        "        return -torch.mean(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcTZ8vDh_WI5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f-koIo0zFkA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "BN=nn.BatchNorm2d\n",
        "\n",
        "__all__ = [\n",
        "    \"ResNet\",\n",
        "    \"resnet20\",\n",
        "    \"resnet32\",\n",
        "    \"resnet44\",\n",
        "    \"resnet56\",\n",
        "    \"resnet110\",\n",
        "    \"resnet1202\",\n",
        "]\n",
        "\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, groups=1, option=\"A\", arrange=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, groups=groups\n",
        "        )\n",
        "        self.bn1 = BN(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False, groups=groups\n",
        "        )\n",
        "        self.bn2 = BN(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == \"A\":\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(\n",
        "                    lambda x: F.pad(\n",
        "                        x[:, :, ::2, ::2],\n",
        "                        (0, 0, 0, 0, planes // 4, planes // 4),\n",
        "                        \"constant\",\n",
        "                        0,\n",
        "                    )\n",
        "                )\n",
        "            elif option == \"B\":\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Conv2d(\n",
        "                        in_planes,\n",
        "                        self.expansion * planes,\n",
        "                        kernel_size=1,\n",
        "                        stride=stride,\n",
        "                        bias=False,\n",
        "                    ),\n",
        "                    BN(self.expansion * planes),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet_Cifar(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, scale=1, groups=1, nc=[16, 32, 64], arrange=[2,1,1]):\n",
        "        super(ResNet_Cifar, self).__init__()\n",
        "        self.in_planes = nc[0] * scale\n",
        "        self.arrange=arrange\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, nc[0] * scale, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = BN(nc[0] * scale)\n",
        "        self.layer1 = self._make_layer(block, nc[0] * scale , num_blocks[0], stride=1, groups=groups)\n",
        "        self.layer2 = self._make_layer(block, nc[1] * scale , num_blocks[1], stride=2, groups=groups)\n",
        "        self.layer3 = self._make_layer(block, nc[2] * scale , num_blocks[2], stride=2, groups=groups)\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride, groups=1):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, groups=groups, arrange=self.arrange))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        return out\n",
        "\n",
        "class ResLTResNet32(nn.Module):\n",
        "      def __init__(self, num_classes=10, scale=1):\n",
        "          super(ResLTResNet32, self).__init__()\n",
        "          nc=[16, 32, 64]\n",
        "          nc=[c * scale for c in nc]\n",
        "          self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "          self.linear = nn.Linear(nc[2], num_classes)\n",
        "          self.model = ResNet_Cifar(BasicBlock, [5, 5, 5], num_classes=num_classes, nc=nc)\n",
        "\n",
        "          # 1x1 conv can be replaced with more light-weight bn layer\n",
        "          self.BNH = nn.BatchNorm2d(nc[2])\n",
        "          self.BNM = nn.BatchNorm2d(nc[2])\n",
        "          self.BNT = nn.BatchNorm2d(nc[2])\n",
        "\n",
        "      def forward(self, x):\n",
        "          out = self.model(x)\n",
        "          head_fs, medium_fs, tail_fs=self.BNH(out), self.BNM(out), self.BNT(out) \n",
        "\n",
        "          fs = torch.cat((head_fs, medium_fs, tail_fs),dim=0)\n",
        "          logits = self.linear(self.avgpool(fs).view(fs.size(0),-1))\n",
        "          c = logits.size(0) // 3\n",
        "          return  logits[:c,:], logits[c:c*2,:], logits[c*2:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaPrO79jxFNx"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHEAQw42xFu-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P28m2C3NzREP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb6f8bb-1c82-4d0e-913c-8dc1496a33a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from networks import nets\n",
        "from datasets import dataset\n",
        "import time\n",
        "import math\n",
        "\n",
        "model_names=['ResLTResNet32']\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "args=Args()\n",
        "args.mark=\"*\"\n",
        "args.epochs=200\n",
        "args.arch='ResLTResNet32'\n",
        "args.start_epoch=1\n",
        "args.lr=0.1\n",
        "args.momentum=0.9\n",
        "args.weight_decay=5e-4\n",
        "args.print_freq=100\n",
        "args.resume=''\n",
        "args.finetune=''\n",
        "args.beta=1.0\n",
        "args.imb_factor=1.0\n",
        "args.scale=1\n",
        "args.cosine=False\n",
        "args.Ti=10\n",
        "args.Ti_mul=2\n",
        "args.lr_min=1e-5\n",
        "args.lr_max=0.1\n",
        "args.dataset='CIFAR10V2'\n",
        "args.num_classes=10\n",
        "args.batch_size=128\n",
        "args.seed=42\n",
        "\n",
        "#parser.add_argument('-mark',type=str,default='')\n",
        "#parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet50', choices=model_names, help='model architecture: ' + ' | '.join(model_names) + ' (default: resnet50)')\n",
        "#parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n",
        "#parser.add_argument('--start-epoch', default=0, type=int, metavar='N', help='manual epoch number (useful on restarts)')\n",
        "#parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\n",
        "#parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
        "#parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float, metavar='W', help='weight decay (default: 1e-4)')\n",
        "#parser.add_argument('--print-freq', '-p', default=100, type=int, metavar='N', help='print frequency (default: 10)')\n",
        "#parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
        "#parser.add_argument('--finetune', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
        "#parser.add_argument('--beta', default=1.0, type=float)\n",
        "#parser.add_argument('--imb_factor', default=None, type=float)\n",
        "#parser.add_argument('--scale', default=1, type=int)\n",
        "\n",
        "###cosine\n",
        "#parser.add_argument('-cosine', default=False, type=bool)\n",
        "#parser.add_argument('-Ti', default=10, type=int)\n",
        "#parser.add_argument('-Ti_mul', default=2, type=int)\n",
        "#parser.add_argument('-lr_min', default=1e-5, type=float)\n",
        "#parser.add_argument('-lr_max', default=0.1, type=float)\n",
        "###dataset\n",
        "#parser.add_argument('-dataset',default='CIFAR10', type=str)\n",
        "#parser.add_argument('-num_classes',default=10, type=int)\n",
        "#parser.add_argument('-b', '--batch-size', default=128, type=int, metavar='N', help='mini-batch size (default: 256)')\n",
        "\n",
        "### random seed\n",
        "#parser.add_argument('-seed',default=None, type=int)\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    if alpha > 0:\n",
        "        lam1 = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "    mixed_x = lam1 * x + (1-lam1) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam1\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam1):\n",
        "    return lam1 * criterion(pred, y_a) + (1-lam1) * criterion(pred, y_b)\n",
        "\n",
        "def crossEntropy(softmax, logit, label, weight):\n",
        "    target = F.one_hot(label, args.num_classes)\n",
        "    loss = - (weight * (target * torch.log(softmax(logit)+1e-7)).sum(dim=1)).sum()\n",
        "    return loss\n",
        "\n",
        "def Train():\n",
        "    os.makedirs(\"Logs/CIFAR10\", exist_ok=True)\n",
        "    os.makedirs(\"checkpoints/CIFAR10/\", exist_ok=True)\n",
        "\n",
        "    ### SEED\n",
        "    if args.seed is not None:\n",
        "       SEED=args.seed\n",
        "       torch.manual_seed(SEED)\n",
        "       torch.cuda.manual_seed(SEED)\n",
        "       np.random.seed(SEED)\n",
        "       torch.backends.cudnn.deterministic=True\n",
        "\n",
        "    #####\n",
        "    data=getattr(dataset,args.dataset)(batch_size=args.batch_size, imb_factor=args.imb_factor)\n",
        "   \n",
        "    #####\n",
        "    model=getattr(nets,args.arch)(num_classes=args.num_classes, scale=args.scale)\n",
        "    model = nn.DataParallel(model)\n",
        "    model=model.cuda()\n",
        "\n",
        "    optimizer=torch.optim.SGD(model.parameters(), lr=args.lr_max if args.cosine else args.lr, momentum=args.momentum,weight_decay=args.weight_decay, nesterov=True)\n",
        "    #ce=torch.nn.CrossEntropyLoss().cuda()\n",
        "    mse=torch.nn.MSELoss().cuda()\n",
        "    kl=nn.KLDivLoss(size_average=False)\n",
        "    softmax=nn.Softmax(dim=1)\n",
        "    ce = RenyiEntropyLoss(alpha=0.4).cuda()\n",
        "    ##### lr schedule cosine\n",
        "    Ti=args.Ti\n",
        "    Ti_mul=args.Ti_mul\n",
        "    lr_min=args.lr_min\n",
        "    lr_max=args.lr_max\n",
        "    last_restart_epoch=0\n",
        "    ##### cosine\n",
        "    def lr_schedule_cosine(epoch,Ti,last_restart_epoch):\n",
        "        T_cur=epoch-last_restart_epoch\n",
        "        if T_cur<Ti:\n",
        "           rate=T_cur/Ti*3.1415926\n",
        "           lr=lr_min+0.5*(lr_max-lr_min)*(1.0+math.cos(rate))\n",
        "        else:\n",
        "           last_restart_epoch=epoch\n",
        "           Ti=int(Ti*Ti_mul+0.5)\n",
        "           T_cur=epoch-last_restart_epoch\n",
        "           rate=T_cur/Ti*3.1415926\n",
        "           lr=lr_min+0.5*(lr_max-lr_min)*(1.0+math.cos(rate))\n",
        "        for param_group in optimizer.param_groups:\n",
        "                param_group['lr']=lr\n",
        "        return lr,Ti,last_restart_epoch\n",
        "\n",
        "    ##### lr multi step schedule\n",
        "    step=[160, 180, 200]\n",
        "    def lr_schedule_multistep(epoch):\n",
        "        if epoch<5:\n",
        "           factor=(epoch+1)/5.0\n",
        "           lr= args.lr * ( 1/3.0 *(1-factor) + factor )\n",
        "        elif epoch<160 * 1 :\n",
        "              lr=args.lr\n",
        "        elif epoch<180 * 1 :\n",
        "              lr=args.lr * 0.1\n",
        "        elif epoch<200 * 1 :\n",
        "              lr=args.lr * 0.1 * 0.1\n",
        "        for param_group in optimizer.param_groups:\n",
        "                param_group['lr']=lr\n",
        "        return lr\n",
        "\n",
        "    #####Train\n",
        "    start_epoch=0\n",
        "    end_epoch=args.epochs\n",
        "    best_acc=0.0\n",
        "    for epoch in range(start_epoch,end_epoch):\n",
        "        #####adjust learning rate every epoch begining\n",
        "        if args.cosine:\n",
        "           lr,Ti,last_restart_epoch=lr_schedule_cosine(epoch,Ti,last_restart_epoch)\n",
        "        else:\n",
        "           lr=lr_schedule_multistep(epoch)\n",
        "        #####\n",
        "\n",
        "        model.train()\n",
        "        train_loss=0.0\n",
        "        total=0.0\n",
        "        correct=0.0\n",
        "        num=0\n",
        "        for i,(inputs,target) in enumerate(data.train):\n",
        "            input, target = inputs.cuda(),target.cuda()\n",
        "            logitH, logitM, logitT = model(input)\n",
        "            ### ResLT \n",
        "            labelH = F.one_hot(target, args.num_classes).sum(dim=1)\n",
        "            labelM = F.one_hot(target, args.num_classes)[:,2:10].sum(dim=1)\n",
        "            labelT = F.one_hot(target, args.num_classes)[:,4:10].sum(dim=1)\n",
        "            loss_ice = (crossEntropy(softmax, logitH, target, labelH) + crossEntropy(softmax, logitM, target, labelM) \\\n",
        "                       + crossEntropy(softmax, logitT, target, labelT)) / (labelH.sum() + labelM.sum() + labelT.sum())\n",
        "\n",
        "            logit = (logitH + logitM + logitT)\n",
        "            loss_fce=ce(logit,target)\n",
        "            loss = loss_ice * args.beta + (1-args.beta) * loss_fce\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss+=loss.item()\n",
        "            _,predicted = logit.max(1)\n",
        "            total += target.size(0)\n",
        "            num+=1\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "            if i % args.print_freq == 0:\n",
        "                acc_n=logit.max(dim=1)[1].eq(target).sum().item()\n",
        "                open(\"Logs/CIFAR10/\"+args.mark+\".log\",\"a+\").write('Train loss %.5f  loss_ice %.5f loss_fce %.5f acc_n %.5f lr %.5f\\n'%(loss.item(), loss_ice.item(), loss_fce.item(), acc_n/input.size(0), lr))\n",
        "        open(\"Logs/CIFAR10/\"+args.mark+\".log\",\"a+\").write(\"Train epoch=%d loss=%.5f  acc=%.5f\\n\"%(epoch,train_loss/num,correct/total))\n",
        "\n",
        "        model.eval()\n",
        "        test_loss=0.0\n",
        "        total=0.0\n",
        "        class_num=torch.zeros(args.num_classes).cuda()\n",
        "        correct=torch.zeros(args.num_classes).cuda()\n",
        "        num=0\n",
        "        for i,(inputs,target) in enumerate(data.test):\n",
        "            input, target = inputs.cuda(),target.cuda()\n",
        "            logitH, logitM, logitT= model(input)\n",
        "            logit = logitH  + logitM + logitT\n",
        "            loss=ce(logit, target)\n",
        "            test_loss+=loss.item()\n",
        "            _,predicted = logit.max(1)\n",
        "            total += target.size(0)\n",
        "            num+=1\n",
        "            target_one_hot=F.one_hot(target,args.num_classes)\n",
        "            predict_one_hot=F.one_hot(predicted,args.num_classes)\n",
        "            class_num=class_num + target_one_hot.sum(dim=0).to(torch.float)\n",
        "            correct=correct + (target_one_hot + predict_one_hot==2).sum(dim=0).to(torch.float)\n",
        "\n",
        "        acc=correct.sum()/total\n",
        "        acc_classes=correct/class_num\n",
        "        head_acc=acc_classes[:3].mean()\n",
        "        medium_acc=acc_classes[3:6].mean()\n",
        "        tail_acc=acc_classes[6:10].mean()\n",
        "\n",
        "        if best_acc<acc:\n",
        "           best_acc=acc\n",
        "           torch.save(model.state_dict(),\"checkpoints/CIFAR10/\"+args.mark+\"_\"+\"best.pth\")\n",
        "\n",
        "        \n",
        "        open(\"Logs/CIFAR10/\"+args.mark+\".log\",\"a+\").write(\"Test epoch=%d loss=%.5f  acc=%.5f best_acc=%.5f\\n\"%(epoch,test_loss/num,correct.sum()/total, best_acc))\n",
        "        open(\"Logs/CIFAR10/\"+args.mark+\".log\",\"a+\").write(\"Test \"+str(correct/class_num)+\"\\n\") \n",
        "        open(\"Logs/CIFAR10/\"+args.mark+\".log\",\"a+\").write(\"Test head acc:\"+str(head_acc)+\" medium acc \"+str(medium_acc)+\" tail acc \"+str(tail_acc)+\"\\n\")\n",
        "\n",
        " \n",
        "#args = parser.parse_args()\n",
        "Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vevBnkHFxKem",
        "outputId": "2723de57-a50f-4365-f5d8-40a16872fc8f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes=[\"c0\",\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\"]\n",
        "count=[5000,2997,1796,1077,645,387,232,139,83,50]\n",
        "plt.bar(classes,count,color='maroon')\n",
        "plt.plot(classes,count,color=\"blue\",linestyle=\"dashed\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Sample Count\")\n",
        "plt.savefig(\"cifar10imb_shape.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s72y0bxv_WI9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}